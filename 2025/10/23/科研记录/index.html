<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>科研记录 | xmdjy's blog</title><meta name="author" content="xmdjy"><meta name="copyright" content="xmdjy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="我也不知道会写啥。。">
<meta property="og:type" content="article">
<meta property="og:title" content="科研记录">
<meta property="og:url" content="https://xmdjy.github.io/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/index.html">
<meta property="og:site_name" content="xmdjy&#39;s blog">
<meta property="og:description" content="我也不知道会写啥。。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://xmdjy.github.io/img/tx.png">
<meta property="article:published_time" content="2025-10-23T11:19:00.000Z">
<meta property="article:modified_time" content="2025-10-26T15:12:30.565Z">
<meta property="article:author" content="xmdjy">
<meta property="article:tag" content="记录">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xmdjy.github.io/img/tx.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "科研记录",
  "url": "https://xmdjy.github.io/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/",
  "image": "https://xmdjy.github.io/img/tx.png",
  "datePublished": "2025-10-23T11:19:00.000Z",
  "dateModified": "2025-10-26T15:12:30.565Z",
  "author": [
    {
      "@type": "Person",
      "name": "xmdjy",
      "url": "https://xmdjy.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/icon.png"><link rel="canonical" href="https://xmdjy.github.io/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;700&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '科研记录',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;700&display=swap" rel="stylesheet"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css"><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/14.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/tx.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/14.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">xmdjy's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">科研记录</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">科研记录</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-23T11:19:00.000Z" title="发表于 2025-10-23 19:19:00">2025-10-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-26T15:12:30.565Z" title="更新于 2025-10-26 23:12:30">2025-10-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">9.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>31分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="think-then-react"><a href="#think-then-react" class="headerlink" title="think-then-react"></a>think-then-react</h2><h3 id="绝对中心tokenizer"><a href="#绝对中心tokenizer" class="headerlink" title="绝对中心tokenizer"></a>绝对中心tokenizer</h3><p>绝对空间tokenizer的目标是把“人在世界坐标中的几何起点与朝向”转成LLM可读的少量离散符号，并且让模型学会“自中心姿态如何推动绝对位姿随时间演进”。它与姿态tokenizer分工清晰：姿态token只描述“身体相对自身怎么动”，空间token只描述“身处何处、面向哪里”。</p>
<p>原理从三件事展开。第一是提取量。世界坐标系约定x–z为水平面、y向上。对每个参与者，在做自中心规范化之前，取骨盆中心的平面位置$(x,z)$与绕y轴的偏航角$r$，并将角度包裹到$(-\pi,\pi]$以处理周期性。这样定义的$(x,z,r)$集中表达了交互几何所需的信息：相互距离、方位与朝向。第二是离散化。对每一维，统计训练集的范围$[v_{\min},v_{\max}]$，做均匀分箱，把连续值$v$映射到桶号<br>$$<br>\mathrm{bin}(v)&#x3D;\left\lfloor \frac{v-v_{\min}}{v_{\max}-v_{\min}}\cdot N_b \right\rfloor\ \text{并夹到}\ [0,N_b-1],<br>$$<br>角度采用“环形分箱”，先把$r$缩放到$[0,2\pi)$再等分为$N_b$个扇区。每个桶对应一个词表项，例如<x7>、<z3>、<r8>。分箱的量化误差在每维不超过半个桶宽，位置误差上界约为$\frac{v_{\max}-v_{\min}}{2N_b}$，角度误差上界约为$\frac{\pi}{N_b}$。论文默认$N_b&#x3D;10$，权衡了词表规模与几何精度。第三是反量化与对齐。把离散桶还原时取桶中心值作为$\tilde x,\tilde z,\tilde r$，并采用角度的环形插值避免跨越$\pm\pi$时的跳变；随后用这些值把自中心解码出来的骨架“旋回+平移”回世界坐标。具体到第$t$步，若自中心骨架关节在局部坐标是$\tilde{\mathbf{p}}<em>{j,t}$，则世界坐标为<br>$$<br>\mathbf{p}</em>{j,t} &#x3D; R_y(r_t),\tilde{\mathbf{p}}_{j,t} + \begin{bmatrix}x_t\ y^{\text{root}}_t\ z_t\end{bmatrix},<br>$$<br>其中$y^{\text{root}}_t$由姿态解码器给出（根高、脚接触等都在姿态侧恢复），$R_y$是绕y轴的旋转矩阵。多人情况下，两个人各自有一组&lt;x·&gt;&lt;z·&gt;&lt;r·&gt;前缀，拼接到各自的姿态token序列之前；两组前缀的差异隐式编码了相对距离与对向关系，供LLM推理交互语义与反应。</p>
<p>工作流分为训练期与推理期两个闭环。训练期，首先对每条序列，逐帧把原始骨架做两步操作：先把每个人的$(x,z,r)$取出做空间token；再对骨架做“平移至原点并旋到+z朝向”的自中心化，生成姿态特征并交给VQ‑VAE量化为姿态token。随后构造联合序列，例如“Action: &lt;xα&gt;&lt;zβ&gt;&lt;rγ&gt;&lt;p…&gt; Reaction: &lt;xμ&gt;&lt;zν&gt;&lt;rξ&gt;&lt;p…&gt;”，用于三类预训练任务。为了让模型学会“姿态如何推动绝对位姿”，特别加入了“姿态→空间”的时间推进任务：给定时刻$t$的空间token和该时刻的姿态token，预测$t+1$的空间token；以及“空间→姿态”的逆任务：给定$t$与$t+1$的空间token，预测其中的姿态token。两项任务把“向前一步”“左转15°”这类自中心动作与绝对位姿的离散更新建立起稳健映射，同时也让LLM在词表层面具备“推进世界坐标”的能力。</p>
<p>推理期，数据流以“空间前缀+已观测动作姿态token”为条件进入LLM。模型先产出“思考”的文本提示，再自回归地产生反应的姿态token。在空间层面有两种常用策略。最简策略只提供初始空间前缀，后续$x_t,z_t,r_t$由模型内部通过学到的姿态→空间关系隐式推进，并在重建阶段用该隐式状态把局部骨架放回世界坐标。更显式的策略是让LLM同时输出稀疏的空间token更新（例如每$k$个姿态token输出一次&lt;x·&gt;&lt;z·&gt;&lt;r·&gt;），用这些离散更新对$x_t,z_t,r_t$做阶梯式或线性插值推进；这种做法在长时程或大幅转身&#x2F;位移时更稳健，也便于控制误差漂移。无论采用哪种策略，最后一步都是把空间token反量化成连续$(x_t,z_t,r_t)$轨迹，再用上式把自中心骨架还原到世界坐标，得到可渲染的绝对3D反应序列。</p>
<p>实现层面的几个细节决定效果与稳定性。范围统计宜对异常值做稳健处理，常用中位数绝对偏差或分位裁剪确定$[v_{\min},v_{\max}]$，避免极端样本让所有桶过宽。角度必须做环形度量，训练时损失使用最小环形差而非线性差。反量化后的$(x_t,z_t,r_t)$可以叠加轻量平滑（如指数滑动平均）消除分箱抖动，同时保持步态的真实微动。分箱精度与词表大小按任务与内存折中调整，$N_b$增大能减小量化误差，但也会放大词表与数据稀疏性；论文用$N_b&#x3D;10$已能在交互级别准确反映“靠近&#x2F;远离、左&#x2F;右转与相对方位”，并把更细的“起伏高度、脚掌滚动”等交给姿态侧连续重建去表达。</p>
<h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><p>预训练的目标，是把通用的LLM变成“懂运动、懂空间、懂语义因果”的多模态序列模型。它围绕三类任务展开：运动-文本、姿态-空间、运动-运动。三者分别把“语义理解与表达”“自中心姿态与绝对位姿的物理对齐”“动作与反应的时间耦合与补全”教给同一个词表与同一套自回归机制，从而为后续“先思考、再反应”的在线生成打下基础。训练层面采用统一的离散词表（空间token与姿态token并入词表），非因果的多任务联合训练，并在整个序列上随机遮盖约15%的token让模型去预测，以提升鲁棒性与泛化；同时用多种模板把同一条样本改写成不同的提示-目标格式，配合随机裁剪片段长度，避免过拟合。不同任务在每个epoch按其验证损失动态调度，困难任务被采样得更频繁。下面分别说明三类任务的作用与具体做法。</p>
<p>运动-文本的作用是把“动作语义”与“语言推理”对齐，让模型学会两件事：从动作里读出语义，以及反过来从语义写出动作。做法上有两个方向。其一是“运动到文本”：把动作与反应的离散表示拼成可读的提示，让模型生成描述。例如输入“Describe the interaction. Action: <x0><z1><r2><p2><p7>… Reaction: <x7><z7><r8><p1><p9>…”，目标输出“一人挥手，另一人回挥”。为了贴近无提示推理的场景，训练时会随机丢弃反应部分，仅用动作去生成整段交互描述，这相当于把“思考”先学会。其二是“文本到运动”：给定一段交互描述，生成动作与反应的离散token序列，格式上依然是“空间token前缀 + 姿态token序列”。这一步把语言和两种运动token放进同一个自回归建模框架里，统一了“说什么”和“怎么动”。这类任务的损失函数是标准的token级交叉熵，跨文本与运动token一体优化；由于非因果训练会在整段上随机遮盖token，模型不仅学习“序列向前”的生成，也学习“补洞”的能力，这在后续在线纠错与再思考时很有用。为了让语义覆盖更广，预训练混入了大量单人“运动-文本”样本，格式完全相同，只是角色从“Action&#x2F;Reaction”退化为“Motion”，这样既不破坏统一词表，又能让姿态码本在更大的语料里收敛。</p>
<p>姿态-空间的作用是把“自中心里的走、转、停”与“世界坐标中的位移与转向”建立起稳定的一步对应，避免仅靠解码阶段的几何变换导致的漂移。它分成两个互逆的小任务。第一个是“姿态到下一步空间”：给定时刻t的空间token与姿态token，预测t+1的空间token，举例说，若输入里包含<z12>与表示“向前迈小步”的<p56>，目标就是<z13>这类“往前一格”的离散更新；这让模型把“自中心迈步”的模式内化为“绝对坐标推进”的离散运算。第二个是“空间到姿态”：给定t与t+1两个相邻的空间token，生成能把“从这里到那里”串起来的姿态token，等价于学会把位姿变化用合理的骨架运动去填充。两项任务共同把“几何—运动”的双向约束灌进词表，推理时即便只给初始空间前缀，模型也能依照已生成的姿态稳定地推进绝对位置与朝向，或者在需要时显式地产生稀疏的空间更新token。训练依旧是token级交叉熵，只是把目标设在空间或姿态分支上；由于采用离散分箱，角度采用环形度量，数据预处理会先把偏航角包裹到(-π,π]再分箱，避免跨越±π时的跳变。</p>
<p>运动-运动的作用是把“动作与反应的因果耦合”和“时间补全”教给模型，直接服务于在线场景的“看前半段、猜后半段”。构造方式是把一段交互切成两半，交叉遮盖让模型补全缺失的另一半。例如把十个时间步的序列切成前5步与后5步，向模型喂“动作1–5步 + 反应6–10步 + 它们各自的空间前缀”，监督它同时补全“动作6–10步与反应1–5步”；或反过来喂“反应1–5步 + 动作6–10步”，预测缺的两段。这样的配对迫使模型在同一上下文里学习互相制约：你怎么动，决定我应当如何起势；我已经起势到了哪，也反推你之前大概率做了什么。这种“时间交叉完形”的学习，正是在线场景里“前看后接、边想边改”的缩影。实现上仍是统一词表、统一交叉熵，区别只是输入输出分段的位置不同。为了增强泛化，还会随机裁剪片段长度与起止点，等价于在各种时长和起势位置上练习“中间接龙”。</p>
<p>把三类任务联起来看，运动-文本把语义桥梁搭起来，让模型会“想”；姿态-空间把几何桥梁搭起来，让模型会“落地”；运动-运动把时间与因果桥梁搭起来，让模型会“接续与修正”。它们都用相同的离散化、相同的词表与同一种自回归&#x2F;填空目标去优化，因此在预训练末期，模型已经能在同一上下文里同时处理文字、空间token与姿态token，这为微调阶段的“先思考、再反应、定期再思考”提供了现成的能力与接口。最后补充一点工程做法：预训练采用非因果的联合训练是为了效率与稳健性——整段随机遮盖能让模型学会双向整合上下文；而在进入微调对接在线推理之前，才切换到因果方式，并逐步从“用真值文本提示”过渡到“用自己生成的思考文本提示”，以消除训练—推理失配。</p>
<h3 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h3><p>微调阶段的目的，是把在多任务预训练中已经学会“看动作、懂语言、会推进空间”的统一模型，专门适配到“在线、无提示”的反应生成流程，并让它在真实推理条件下稳定运行。微调严格改用因果式训练（左到右掩码），把任务收敛到两条闭环：先“思考”（动作理解与反应语义推断），再“反应”（基于思考去生成反应动作），并在训练中显式模拟在线条件与误差来源，从而减少训练—推理失配。</p>
<p>首先是思考任务。输入只包含动作方的空间前缀和已观测到的部分动作姿态token，长度被随机裁成四分之一、一半或全段，迫使模型在证据不充分时也要输出完整的交互描述与期望的反应描述，相当于把“在不确定早期先假设、随后逐步修正”的能力练出来。训练目标是标准的交叉熵，预测的是文本token序列，不再做预训练里的全局遮盖，而是完全按因果方式左到右生成。这样训练出来的“思考”头，与推理时“每过Nr个姿态token就重新思考一次”的策略是同构的；不同之处在于推理要周期性重启思考，训练则通过“只给前25%、50%、100%动作”的多样化输入去覆盖这些状态。</p>
<p>其次是反应任务。它要在已有的动作token与刚刚生成的思考文本提示之上，自回归地产生反应者的姿态token序列，并据已学到的姿态→空间映射推进绝对位姿。这里最大的训练—推理差异来自“文本提示”的噪声：推理时用的是模型自己生成的思考文本，而早期模型的文本尚不稳定。为此采用教师强制的渐进日程：微调前期把真值描述作为反应条件，让模型先把“如何在给定正确提示下生成高质量反应”学牢；随着验证集上的文本生成指标与整体loss收敛，开始用模型自己采样出的思考文本替换一部分真值提示，并逐步提高替换比例，直到主要依赖自生成提示。这一步相当于做自条件训练，把暴露偏差降到最低，使得推理时的语义噪声不再导致反应崩溃。反应的监督同样是token级交叉熵，目标是反应者的姿态token；空间推进不需要额外监督，因为在预训练里已通过“姿态→空间&#x2F;空间→姿态”任务把几何演化学入了词表预测。</p>
<p>输入输出格式在微调中保持与推理一致。一个训练样本会以“动作方的空间前缀 + 已观测动作姿态token”开头，后面接“思考段落”的文本目标，再接“反应段落”的姿态token目标。模型用同一个词表和同一套LM头分别预测文本与运动token，位置编码与注意力掩码保证严格的左到右因果性。为贴近在线时长约束，反应段的目标长度与动作段对齐，超出部分用终止符截断。训练中不再做随机mask，而通过随机截断观测窗来制造不确定性；同一batch内会混合不同截断比例，使模型在“很早、半程、全程”三种证据强度下都能合理思考与生成。</p>
<p>优化与调度方面，微调继续用预训练时扩展过的词表与同一骨干（论文用Flan‑T5‑base），学习率保持1e‑4并采用早停；batch大小为32，总步数约四万。思考与反应两个子任务在样本级交替混合，初期更偏重反应以尽快稳定运动生成，随后增大思考样本占比以提升语义判断的鲁棒性。重思考间隔Nr不作为可学习参数，而是在推理策略里固定为4个姿态token；不过训练通过不同截断比例自然覆盖了“重思考前后”的状态分布，使得固定Nr在实测上达到较好折中。为避免用自生成文本时的灾难性偏移，采样阶段通常限制温度与核采样阈值，或直接用贪心&#x2F;小温度生成思考文本，再用略高的多样性去生成动作；这一点与论文的总体设置一致，即优先保障语义稳定，再体现动作的合理变化。</p>
<p>总体而言，微调把“预训练学到的三座桥”——语义桥（运动‑文本）、几何桥（姿态‑空间）与时间&#x2F;因果桥（运动‑运动）——在因果框架下串联起来，并用教师强制到自条件的渐进日程对齐推理时的真实闭环。从而实现了推理期的工作形态：观察动作→生成&#x2F;更新思考→据此生成下一段反应→到点再思考纠偏→持续在线输出；这也是实验里长序列胜出的关键。</p>
<h2 id="StreamForest"><a href="#StreamForest" class="headerlink" title="StreamForest"></a>StreamForest</h2><p>pipeline：<br>这里用流程化的叙述把 StreamForest 的端到端 pipeline 串起来（以论文本身为准：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.24871%EF%BC%89%E3%80%82">https://arxiv.org/abs/2509.24871）。</a></p>
<p>视频以 1 FPS 连续到达后，首先经视觉编码器与投影器被映射为一批视觉 token；系统立即把这些 token 分流到两条并行路径：一条是“精细时空窗口”（FSTW）以高保真刻画当前时刻及最近若干秒的细粒度动态，另一条是“持久事件记忆森林”（PEMF）以事件为单位组织与压缩更长时间尺度的历史。</p>
<p>在 FSTW 路径中，当前帧保留较高分辨率的空间 token 并编码时空位置信息；随着新帧不断到来，较旧的帧会在空间维度上被压缩转存为“短期时空记忆”，系统同时在这个短窗内计算相邻帧间的相似度曲线，用其局部极小值来切分出“元事件”（meta‑events），每个元事件聚合相似的连续帧 token，既保留近因的动作细节（比如小幅姿态变化、速度&#x2F;接近度变化），又把可直接离线的冗余压下来。当短期记忆超过容量或形成新的元事件时，这些元事件会被“卸载”到长期记忆端。</p>
<p>在 PEMF 路径中，来自 FSTW 的元事件被作为叶节点插入到一组按时间生长的事件树中；为保证整体视觉 token 不超过给定预算 Lq，PEMF在每次插入或预算超限时，对相邻事件节点计算综合代价并执行自适应合并。综合代价由三项惩罚加权得到：内容相似度惩罚 $Ps$ 鼓励合并视觉上高度相似的相邻事件（用双向匹配取 Top‑K token 对相似度的均值），合并计数惩罚 $Pm$ 抑制某些节点被过度多轮合并导致细节退化，时间距离惩罚 $Pt$ 倾向优先保留离查询时刻更近的细节并更激进地压缩久远历史；总体分数为 $P &#x3D; w_s Ps + w_m Pm + w_t Pt$（默认权重 0.4&#x2F;0.4&#x2F;0.2）。系统总是选择 $P$ 最小的相邻节点对，采用 ToMe 式 token 合并把两者 token 压到约一半，同时用“按 token 数加权平均”的方式更新新节点的时间戳并累加合并计数。如此循环，PEMF把长时历史组织成层级化的事件森林，既去除了局部冗余，又保留了关键的事件级证据链。</p>
<p>当任意时刻发生用户查询（时间 $t_q$）时，系统从两条路径聚合上下文：FSTW 提供当前帧的高分辨率 token 加上短期时空记忆中的压缩 token，PEMF 提供各棵事件树的根节点 token；这些视觉 token 与文本一起送入多模态 LLM，完成答案生成或未来风险&#x2F;行为前瞻等推理。查询完毕后，流式循环继续：新帧进入、FSTW 更新、产生新的元事件并插入&#x2F;触发 PEMF 的自适应合并；由于 Lq 对视觉 token 设定了硬上限，计算与显存随视频时长基本保持稳定，从而支撑长时间不间断的在线动作理解与前瞻预测。</p>
<p>森林更新规则<br>下面只讲 StreamForest 的“持久事件记忆森林（PEMF）”本体：它长什么样、节点长什么样、以及新节点如何加入并触发合并。为方便核对，术语与公式均对应论文原文（<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.24871%EF%BC%89%E3%80%82">https://arxiv.org/abs/2509.24871）。</a></p>
<p>PEMF 的结构可以理解为“按时间顺序生长的一组事件树”，因此称作森林而不是单棵树。叶子对应从精细时空窗口（FSTW）切出的“元事件”，内部节点对应两个相邻事件经一次合并后的更高层级事件表示。森林中的每一棵树覆盖时间轴上的一个连续区间；各树的根节点共同构成“长期记忆前沿”，查询时就是把这些根节点的视觉表示与 FSTW 的近因细节一起喂入 LLM。这样做保持了两条不变性：所有节点都带有清晰的时间区间，且根节点两两互不重叠、按时间从早到晚有序排列，因而森林是对整段历史的“分段层级摘要”。</p>
<p>节点的数据结构至少包含四类信息。第一，视觉token集合及其维度（来自多帧聚合或合并之后的token）；第二，时间戳与时间跨度：时间戳用于度量该节点的“位于整段历史的何处”，论文采用按token数加权的时间均值来避免多轮合并后的漂移，公式为<br>$$<br>t_{\mathrm{new}}&#x3D;\frac{t_i n_i + t_j n_j}{n_i+n_j},<br>$$<br>其中 $n_i,n_j$ 是子节点 token 数。第三，历史合并计数 $c$，用于记录该节点在层级化压缩中“被动参与”的次数，以辅助抑制过度合并导致的细节退化。第四，关于相似度或统计量的缓存，用于快速评估与相邻节点的合并代价（实现上是否缓存属于工程自由度，文中只规定了代价的计算方式）。</p>
<p>新节点的加入是严格按时间顺序进行的。当 FSTW 在短窗内检测到一个元事件边界时，会把这一段连续帧聚合成一份紧凑表示，作为“单节点小树”附加到森林的末尾。此时森林的根节点序列等价于“当前可见的顶层事件分段”序列，新增的单节点会作为最新的一个根加入序列。加入后立即执行预算检查：若森林内所有根节点的 token 总量不超过长期记忆上限 $L_q$（由总预算扣除 FSTW 固定配额得到），就不做任何改动；一旦超过 $L_q$，就启动一轮或多轮相邻合并，直到总量回到预算之内。</p>
<p>合并只发生在时间相邻的节点对之间，以避免跨段融合破坏时间连续性。对于每一对相邻根节点 $(x_i, x_{i+1})$，系统计算一个加权代价<br>$$<br>P(x_i,x_{i+1}) ;&#x3D;; w_s,P_s ;+; w_m,P_m ;+; w_t,P_t,<br>$$<br>并总是选择 $P$ 最小的那一对优先合并。三项子代价分别刻画“内容冗余”“合并疲劳”“时间远近”的权衡：相似度惩罚 $P_s$ 倾向合并视觉上高度相似的相邻片段，计算上把两节点的 token 视作二部图两侧，取 Top‑K 余弦相似度的平均再做 $1-$ 变换得到<br>$$<br>P_s ;&#x3D;; 1 - \frac{1}{k}\sum_{(p,q)\in \mathrm{TopK}} \mathrm{sim}(X_i^{(p)},X_{i+1}^{(q)}).<br>$$<br>合并计数惩罚 $P_m$ 用于抑制某个节点被频繁压缩导致的信息流失，采用归一化的平均计数<br>$$<br>P_m ;&#x3D;; \frac{c_i + c_{i+1}}{2c_{\max}},<br>$$<br>其中 $c_{\max}$ 是到当前时刻观察到的最大合并计数，用作尺度化。时间距离惩罚 $P_t$ 体现“近因优先保真、远因更可压缩”的原则，记 $t_q$ 为查询或当前时间、$t_i$ 为节点时间，先做归一化距离 $d_i&#x3D;(t_q-t_i)&#x2F;t_q$，再取<br>$$<br>P_t ;&#x3D;; 1 - \frac{d_i + d_{i+1}}{2}.<br>$$<br>权重 $(w_s,w_m,w_t)$ 控制三种策略的相对强度：只开 $P_s$ 会退化为纯相似度合并，只开 $P_t$ 近似 FIFO，只开 $P_m$ 类似均匀下采样；论文默认采用 $0.4&#x2F;0.4&#x2F;0.2$ 的平衡配置。</p>
<p>一旦选定要合并的相邻节点对，系统采用 ToMe 风格的 token 合并把两者的 token 压到原总量的大约一半，同时生成一个新的父节点，作为这两个节点的上层表示。新节点的时间戳按前述加权公式计算，合并计数在子节点的基础上更新（论文不强制具体函数形式，常见做法是对子节点计数做聚合后自增一，以反映“完成一次新合并”）。随后用新节点替换原先的那一对，把它放回到相同的时间位置，继续检查预算；如果仍然超限，就在更新后的“相邻对”集合里再次选择 $P$ 最小的一对继续合并。这个过程保证了森林顶层的根节点数和每个根节点的 token 量都被约束在预算内，同时尽量保留对下游推理最有价值的事件级信息：视觉上高度冗余或时间上久远的部分更可能被合并，而合并次数过多、可能已损失细节的节点会因为 $P_m$ 偏大而被“保护”，避免进一步退化。</p>
<p>从整体上看，PEMF 的“结构—加入—合并”逻辑确保了三件事同时成立：历史被划分成若干时间连续的“树段”，每段内部是自下而上的事件层级；所有段的根节点共同覆盖全部已见历史且不重叠；长期记忆严格受 $L_q$ 约束而不会随视频长度线性膨胀。查询阶段只需取各根节点的表示与 FSTW 的近因细粒度表示拼接，即可在固定预算下把“远因脉络”和“近因征兆”一起交给 LLM 做因果与前瞻推理。</p>
<p>插入顺序<br>简短结论：新元事件从 FSTW 溢出后，按时间顺序作为“最右侧”的最新叶子节点追加到 PEMF 的底层序列中；相邻关系按时间相邻定义。也就是说，插入位置由该元事件的时间戳决定，保持整个事件序列的单调递增。随后若超出可视化 token 上限，再依据三种惩罚组成的优先级在相邻对中触发合并，通常优先合并更早、更相似、合并次数多的老节点，而不是刚插入的新节点。</p>
<p>原因与依据如下。FSTW在短期窗口内以帧间相似度的局部最小值切分出“元事件”，被卸载时这段元事件的时间戳取它覆盖帧的平均时间：$t_{\text{node}}&#x3D;\frac{1}{n}\sum_k t_k$。在线流是单调前进的，因此每次产生的元事件时间戳都晚于已在PEMF中的最后一个节点，插入只需在时间轴的末端追加，形成与前一节点的新的相邻对。如一次卸载产生多个元事件，也按它们各自的时间戳顺序依次追加。PEMF内部的“相邻”即时间相邻，后续所有合并候选都只在这些相邻对 $(x_i,x_{i+1})$ 上计算综合惩罚<br>$$<br>P(x_i,x_{i+1})&#x3D;w_s P_s+w_m P_m+w_t P_t,<br>$$<br>其中时间距离项 $P_t$ 让靠近当前查询时刻 $t_q$ 的新节点不易被立刻合并（$d_i&#x3D;(t_q-t_i)&#x2F;t_q$ 越小，越应保留）。因此实际行为是：先按时间戳把新元事件追加为最新相邻节点；如触发容量约束，再在全局相邻对里按惩罚最小的那一对做合并，通常发生在更早的那一侧，从而既维持时间顺序又保持长期记忆的紧凑性。</p>
<h2 id="PEMF"><a href="#PEMF" class="headerlink" title="PEMF"></a>PEMF</h2><p>持久事件记忆森林（Persistent Event Memory Forest, PEMF）是为“超长流式视频、固定显存&#x2F;算力预算、需要实时问答”这一矛盾而设计的长期记忆机制。它的目标是在总视觉 token 上限不变的情况下，尽可能长期、稳定地保存过去关键事件，同时避免把近处的细节压坏，让模型既能记住很久以前的关键信息，又能在当前时刻保持细粒度感知。</p>
<p>首先说它存什么、怎么存。来自细粒度时空窗口的最近帧，会被持续计算帧间相似度，并在相似度曲线的局部极小点处分段，切成一段段“元事件”。每个元事件被当作一个独立节点，包含从若干相似的连续帧汇聚而来的视觉 token，并携带时间戳（取该段帧的平均时间）与“合并次数”计数。这些事件节点并不是简单地排成一条长链，而是会被逐步组织成若干棵树，形成“森林”。一棵树的根节点代表了一段更长时间范围内的汇总表示；随着时间推移和内存压力增加，底层相邻事件会被向上合并，形成更抽象的父节点。这样“事件级”的层次化组织，比按帧直接压缩更不容易把时序结构搅乱。</p>
<p>其次是“有上限、如何守住上限”。PEMF对“长期记忆的视觉 token 总数”设定了一个硬上限 Lq；整个模型还有一个全局视觉 token 上限（默认约 8192）。当新事件写入导致超过配额时，PEMF不会盲目丢帧，而是只在“相邻事件节点对”里挑一对“最该合并”的来做层次化整合，直到把总量拉回上限。谁“最该合并”，由三个惩罚项加权决定：相似度惩罚、合并次数惩罚、时间距离惩罚。</p>
<p>相似度惩罚衡量两段是否“内容冗余”。设相邻两个事件节点的视觉 token 矩阵分别为 $X_i \in \mathbb{R}^{n_i \times d}$、$X_{i+1} \in \mathbb{R}^{n_{i+1} \times d}$，计算两集合 token 的两两余弦相似度矩阵 $S_i \in \mathbb{R}^{n_i \times n_{i+1}}$，取其前 $k_i$ 个最高相似度配对的平均，定义<br>$$<br>P_s(x_i, x_{i+1}) ;&#x3D;; 1 ;-; \frac{1}{k_i}\sum_{(p,q)\in \text{TopK}(S_i, k_i)} S_i^{(p,q)}.<br>$$<br>相似度越高，$P_s$越小，意味着越应该被优先合并。</p>
<p>合并次数惩罚抑制“反复压扁同一段”导致的细节劣化。记节点 $x_i$ 历史合并次数为 $c_i$，当前全局最大合并次数为 $c_{\max}$，定义<br>$$<br>P_m(x_i, x_{i+1}) ;&#x3D;; \frac{c_i + c_{i+1}}{2,c_{\max}}.<br>$$<br>合并得越多，$P_m$ 越大，越不应再被合并，有助于在时间轴上更均衡地保留细节。</p>
<p>时间距离惩罚体现“就近保真、远处可更粗”的策略。设当前交互时刻为 $t_q$，节点时间戳为 $t_i$，定义归一化“距离现在的相对时间”$d_i &#x3D; \frac{t_q - t_i}{t_q}$，则<br>$$<br>P_t(x_i, x_{i+1}) ;&#x3D;; 1 ;-; \frac{d_i + d_{i+1}}{2}.<br>$$<br>离现在越近，$d$ 越小、$P_t$ 越大，表示不应被合并；很久以前的事件 $P_t$ 小，更倾向被汇总。</p>
<p>三者线性加权得到总惩罚<br>$$<br>P(x_i, x_{i+1}) ;&#x3D;; w_s P_s ;+; w_m P_m ;+; w_t P_t,<br>$$<br>权重控制策略风格。只开相似度惩罚就退化为“相似度压缩”；只开合并次数惩罚近似“均匀降采样”；只开时间距离惩罚接近“FIFO”。论文默认用 $w_s{&#x3D;}0.4,, w_m{&#x3D;}0.4,, w_t{&#x3D;}0.2$，在多种基准上给出了较好的平衡。</p>
<p>选出总惩罚最小的相邻节点对后执行合并。合并本质是一个事件级的 token 合并操作：把两段的视觉 token 通过匹配与聚合压到总量的一半左右，生成新的父节点；父节点的时间戳用“按 token 数加权的平均”更新<br>$$<br>t_{\text{new}} ;&#x3D;; \frac{t_i \cdot n_i + t_j \cdot n_j}{n_i + n_j},<br>$$<br>并把合并次数计数递增。这样既压缩了冗余，也抑制了由于事件长度差异导致的时间戳漂移。在达到配额之前，PEMF只接纳来自短期窗口切好的元事件节点；一旦达到或超出配额，就循环“挑对—合并”，直到回到预算以内。由于整个过程中“每次只减局部的、最不重要的那一对”，森林的规模被严格约束，显存和延迟不会随已处理帧数线性增长。</p>
<p>在查询阶段，模型把全部根节点的视觉表示与短期窗口的细粒度表示一起，经由投影头映射到 LLM 的嵌入空间，与文本序列拼接，一次前向统一建模。这样 LLM 能同时看到“当前细节”和“长期语义摘要”，并通过注意力自动把与问题时间或语义最相关的节点“拉近”。如果问题指向很久之前的时刻，主要证据来自对应时间附近的根节点；如果指向此刻或刚刚发生的内容，细节更多来自短期窗口。</p>
<p>从工程与效果上看，PEMF最重要的两个特性是“事件级而非帧级压缩”与“带偏好的局部合并”。事件级压缩能避免相似度合并在局部连续帧上过度动作、打乱原本连贯的行为单元；而三惩罚共同作用能在“去冗余、保持时间连续性、抑制过度合并、保护近处细节”之间取得可调的平衡。配合固定的视觉 token 上限，推理的显存与吞吐基本稳定；在极端小预算下，整体语义与证据召回仍保持较高水平。需要更偏“回忆远处历史”时，可以降低时间距离惩罚权重或增大长期配额；需要更稳地保护近期细节时，可以相应提高时间距离惩罚或短期窗口配额。其局限也很清楚：事件边界目前基于外观相似度的局部极小值，语义上未必总是完美，因而在极端复杂的历史中，远处的细节会不可避免地被摘要成更粗的表示；论文也讨论了未来可引入轻量语义提醒模块，进一步提升边界与输出时机的语义准确性。</p>
<h2 id="P-s-h定义"><a href="#P-s-h定义" class="headerlink" title="$P_s$h定义"></a>$P_s$h定义</h2><p>相似度惩罚 $P_s$ 的目标是量化“相邻两个事件节点在内容上有多相似”，越相似越应该优先合并。设相邻两个事件节点的视觉 token 特征分别为 $X_i \in \mathbb{R}^{n_i \times d}$ 与 $X_{i+1} \in \mathbb{R}^{n_{i+1} \times d}$，其中每一行是一个 $d$ 维的视觉 token 表征。由于两段时长不同，$n_i$ 与 $n_{i+1}$ 往往不相等，不能直接做一一对应比较，因此采用“跨集合两两比较”的方式构建余弦相似度矩阵，然后只关注其中“最相似的若干对”。</p>
<p>首先计算帧间余弦相似度矩阵。对每个 token 向量做 $L_2$ 归一化，记<br>$$<br>\hat{X}<em>i[p] ;&#x3D;; \frac{X_i[p]}{\lVert X_i[p]\rVert_2 + \varepsilon}, \qquad<br>\hat{X}</em>{i+1}[q] ;&#x3D;; \frac{X_{i+1}[q]}{\lVert X_{i+1}[q]\rVert_2 + \varepsilon}.<br>$$<br>这样任意一对 token 的余弦相似度<br>$$<br>S_i^{(p,q)} ;&#x3D;; \frac{X_i[p]\cdot X_{i+1}[q]}{\lVert X_i[p]\rVert_2,\lVert X_{i+1}[q]\rVert_2}<br>;&#x3D;; \hat{X}<em>i[p]\cdot \hat{X}</em>{i+1}[q],<br>$$<br>数值范围在 $[-1,1]$。将所有 $(p,q)$ 的相似度排成矩阵 $S_i \in \mathbb{R}^{n_i \times n_{i+1}}$。在实现上，先对两边做行向量归一化，然后一行代码即可得到整块相似度矩阵：$S_i&#x3D;\hat{X}<em>i,\hat{X}</em>{i+1}^{\top}$；加上一个很小的 $\varepsilon$ 主要是数值稳定。</p>
<p>接着做“局部的近似双边匹配”。因为两段 token 数不同、且并非每个 token 都重要，如果对整个矩阵求平均会被背景或噪声 token 稀释，所以只挑出“最相似的 $k_i$ 对 token”来代表两段的重合度。论文写作上用<br>$$<br>T_i ;&#x3D;; \operatorname{argTopK}<em>{(p,q)}\big(S_i,, k_i\big)<br>$$<br>来表示在矩阵 $S_i$ 中选出分值最高的 $k_i$ 个条目（即 $k_i$ 对 $(p,q)$ 索引）。这相当于对 ToMe 中“一对多&#x2F;多对一”的轻量匹配思想的一个近似实现，比起求严格的一对一最优匹配（如匈牙利算法）要高效很多。在实践中，$k_i$ 可以设为 $\min(n_i, n</em>{i+1})$，也可以设为一个上限值以控制计算稳定性与鲁棒性。</p>
<p>有了这 $k_i$ 对最高相似度的 token 配对，先求它们的平均相似度，再把“相似度”转为“惩罚”，定义为<br>$$<br>P_s(x_i, x_{i+1}) ;&#x3D;; 1 ;-; \frac{1}{k_i}\sum_{(p,q)\in T_i} S_i^{(p,q)}.<br>$$<br>如果两段内容几乎一致，那么前 $k_i$ 个相似度会接近 1，平均值也接近 1，于是 $P_s\approx 0$，表示“非常该合并”；如果两段内容差异很大，前 $k_i$ 个相似度也不会高，平均值接近 0，$P_s\approx 1$，表示“尽量不要合并”。</p>
<p>这样设计有三个关键点。第一，先做向量归一化，把点积直接等同于余弦相似度，矩阵乘法就得到所有两两相似度，既高效又稳定。第二，只用前 $k_i$ 个高分匹配对，避免了背景 token 拉低平均值，也不用为一对一精确匹配付出高昂代价；不同长度的事件段也能公平比较。第三，把“相似度的平均”翻转成“惩罚”，便于与另外两个惩罚项（时间距离、合并次数）做加权求和，统一到“数值越小越优先合并”的选择规则里。</p>
<p>实现细节上，计算量主要在构造 $S_i$，复杂度近似 $O(n_i n_{i+1} d)$。因为事件节点的 token 数通常已经被 FSTW 与前序合并压缩到较小规模（例如百级别 token），这一步在流式更新里是轻量的。为了数值稳定与速度，常见做法是先对 $X_i$、$X_{i+1}$ 做行归一化，再用矩阵乘法直接得到 $S_i$；选择 $k_i$ 时既要覆盖主要的“语义重叠”，又要避免把低质量的长尾配对纳入统计，经验上设置成较小的比例或取两边 token 数的较小值效果较稳。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://xmdjy.github.io">xmdjy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://xmdjy.github.io/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/">https://xmdjy.github.io/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://xmdjy.github.io" target="_blank">xmdjy's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%B0%E5%BD%95/">记录</a></div><div class="post-share"><div class="social-share" data-image="/img/tx.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/10/16/plan/" title="科研计划"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">科研计划</div></div><div class="info-2"><div class="info-item-1">近期需要做的事情：  实验复现：think-then-react的eval和train的代码详细内容(看训练的细节)   动作生成 - THINK-THEN-REACT: TOWARDS UNCONSTRAINED  HUMAN ACTION-TO-REACTION GENERATION 视频理解 - StreamForest: Efficient Online Video Understanding with Persistent Event Memory 视频理解 - Online Video Understanding: OVBench and VideoChat-Online 动作模型 - MotionLLM: Understanding Human Behaviors from Human Motions and Videos 动作理解 - RHINO: Learning Real-Time  Humanoid-Human-Object Interaction  from Human Demonstrations同时关注NJU-MCG组的工作以及RUC-GSAI的相关工...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/tx.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">xmdjy</div><div class="author-info-description">welcome to my blog</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xmdjy"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/xmdjy" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1833299761@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1833299761&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #12b7f5;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">a blog written by xmdjy</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#think-then-react"><span class="toc-number">1.</span> <span class="toc-text">think-then-react</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9D%E5%AF%B9%E4%B8%AD%E5%BF%83tokenizer"><span class="toc-number">1.1.</span> <span class="toc-text">绝对中心tokenizer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-number">1.2.</span> <span class="toc-text">预训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83"><span class="toc-number">1.3.</span> <span class="toc-text">微调</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#StreamForest"><span class="toc-number">2.</span> <span class="toc-text">StreamForest</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PEMF"><span class="toc-number">3.</span> <span class="toc-text">PEMF</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#P-s-h%E5%AE%9A%E4%B9%89"><span class="toc-number">4.</span> <span class="toc-text">$P_s$h定义</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/23/%E7%A7%91%E7%A0%94%E8%AE%B0%E5%BD%95/" title="科研记录">科研记录</a><time datetime="2025-10-23T11:19:00.000Z" title="发表于 2025-10-23 19:19:00">2025-10-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/16/plan/" title="科研计划">科研计划</a><time datetime="2025-10-16T11:19:00.000Z" title="发表于 2025-10-16 19:19:00">2025-10-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/17/%E6%95%B0%E7%BB%84/" title="算法详解：二分查找的原理与实现">算法详解：二分查找的原理与实现</a><time datetime="2025-09-17T02:00:00.000Z" title="发表于 2025-09-17 10:00:00">2025-09-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/19/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/" title="强化学习的数学原理">强化学习的数学原理</a><time datetime="2025-08-18T16:00:00.000Z" title="发表于 2025-08-19 00:00:00">2025-08-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/15/hello-world/" title="Hello World">Hello World</a><time datetime="2025-08-15T01:41:21.358Z" title="发表于 2025-08-15 09:41:21">2025-08-15</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By xmdjy</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div><div class="footer_custom_text">驱动框架💕 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> | 博客主题✨ <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>